/***************************************************************************
 *  tag_vision_thread.cpp - Thread to print the robot's position to the log
 *
 *  Created: Thu Sep 27 14:31:11 2012
 *  Copyright  2012  Tim Niemueller [www.niemueller.de]
 ****************************************************************************/

/*  This program is free software; you can redistribute it and/or modify
 *  it under the terms of the GNU General Public License as published by
 *  the Free Software Foundation; either version 2 of the License, or
 *  (at your option) any later version.
 *
 *  This program is distributed in the hope that it will be useful,
 *  but WITHOUT ANY WARRANTY; without even the implied warranty of
 *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 *  GNU Library General Public License for more details.
 *
 *  Read the full text in the LICENSE.GPL file in the doc directory.
 */

#include "conveyor_vision_thread.h"

#include <tf/types.h>
#include <interfaces/Position3DInterface.h>

//#include <opencv/cv.h>
#include <math.h>

#define CFG_PREFIX "/plugins/conveyor_vision/"
#define IMAGE_CHANNELS 3

using namespace fawkes;
using namespace std;
using namespace cv;

/** @class ConveyorVisionThread "tag_vision_thread.h"
 * Thread to identify AR Tags and provid e their position
 * @author Nicolas Limpert & Randolph MaaÃŸen
 */

/** Constructor. */
ConveyorVisionThread::ConveyorVisionThread()
  : Thread("ConveyorVisionThread", Thread::OPMODE_WAITFORWAKEUP),
    VisionAspect(VisionAspect::CYCLIC),
    ConfigurationChangeHandler(CFG_PREFIX),
    fawkes::TransformAspect(fawkes::TransformAspect::ONLY_PUBLISHER,"conveyor")
{
    fv_cam = NULL;
    shm_buffer = NULL;
    image_buffer = NULL;
    ipl = NULL;
//    this->markers_ = NULL;
}

void
ConveyorVisionThread::init()
{
   std::string prefix = CFG_PREFIX;
   std::string mps_cascade_name = (string)config->get_string((prefix + "classifier_file"));
   if( !mps_cascade.load( std::string(CONFDIR) + "/" + mps_cascade_name ) ){ printf("--(!)Error loading\n"); return; };

//   fawkes::Position3DInterface* puck_if_ = NULL;
    try {
            mps_conveyor_if_ = blackboard->open_for_writing<fawkes::Position3DInterface>("mps_conveyor");
//            puck_if_->set_frame(camera_info_.frame.c_str());
            mps_conveyor_if_->write();
//            puck_interfaces_.push_back(puck_if_);
    }catch (std::exception &e) {
            finalize();
            throw;
    }

    config->add_change_handler(this);
    // load config
    // config prefix in string for concatinating
//    std::string prefix = CFG_PREFIX;
    // log, that we open load the config
    logger->log_info(name(),"loading config");
    load_config();
    // load alvar camera calibration
//    if(!alvar_cam.SetCalib(config->get_string((prefix + "classifier_file").c_str()).c_str(),0,0,FILE_FORMAT_DEFAULT))
//    {
//      this->logger->log_warn(this->name(),"Faild to load calibration file");
//    }
//    // load marker size and apply it
//    marker_size = config->get_uint((prefix + "marker_size").c_str());
//    detector.SetMarkerSize(marker_size);

    //Image Buffer ID

    // init firevision camera
    // CAM swapping not working (??)
    if(fv_cam != NULL){
        // free the camera
        fv_cam->stop();
        fv_cam->flush();
        fv_cam->dispose_buffer();
        fv_cam->close();
        delete fv_cam;
        fv_cam = NULL;
    }
    if(fv_cam == NULL){
      std::string connection = this->config->get_string((prefix + "camera").c_str());
        fv_cam = vision_master->register_for_camera(connection.c_str(), this);
        fv_cam->start();
        fv_cam->open();
        this->img_width = fv_cam->pixel_width();
        this->img_height = fv_cam->pixel_height();
    }

    //set camera resolution
//    alvar_cam.SetRes(this->img_width, this->img_height);

    // SHM image buffer
    if(shm_buffer != NULL) {
        delete shm_buffer;
        shm_buffer = NULL;
        image_buffer = NULL;
    }

    shm_buffer = new firevision::SharedMemoryImageBuffer(
                shm_id.c_str(),
                firevision::YUV422_PLANAR,
                this->img_width,
                this->img_height
                );
    if(!shm_buffer->is_valid()){
        delete shm_buffer;
        delete fv_cam;
        shm_buffer = NULL;
        fv_cam = NULL;
        throw fawkes::Exception("Shared memory segment not valid");
    }
    std::string frame = this->config->get_string((prefix + "frame").c_str());
    shm_buffer->set_frame_id(frame.c_str());

    image_buffer = shm_buffer->buffer();
    ipl =  cvCreateImage(
                cvSize(this->img_width,this->img_height),
                IPL_DEPTH_8U,IMAGE_CHANNELS);


    // set up marker
    world_pos_z_average = 0.;
    max_marker = 16;
//    this->markers_ = new std::vector<alvar::MarkerData>();
//    this->tag_interfaces = new TagPositionList(this->blackboard,this->max_marker,frame,this->name(),this->logger, this->clock, this->tf_publisher);

}

void
ConveyorVisionThread::finalize()
{
  vision_master->unregister_thread(this);
  config->rem_change_handler(this);
  // free the markers
//  this->markers_->clear();
//  delete this->markers_;
  delete fv_cam;
  fv_cam = NULL;
  delete shm_buffer;
  shm_buffer= NULL;
  image_buffer = NULL;
//  cvReleaseImage(&ipl);
  ipl = NULL;
//  delete this->tag_interfaces;
}

void
ConveyorVisionThread::loop()
{
    if(!cfg_mutex.try_lock()){
        //logger->log_info(name(),"Skipping loop");
        return;
    }
    if(fv_cam == NULL || !fv_cam->ready()){
        logger->log_info(name(),"Camera not ready");
        init();
        return;
    }
    //logger->log_info(name(),"entering loop");
    //get img form fv
    fv_cam->capture();
    firevision::convert(fv_cam->colorspace(),
                        firevision::YUV422_PLANAR,
                        fv_cam->buffer(),
                        image_buffer,
                        this->img_width,
                        this->img_height);
    fv_cam->dispose_buffer();
    //convert img
    firevision::IplImageAdapter::convert_image_bgr(image_buffer, ipl);
    frame = Mat(ipl);
    detect();
    mps_conveyor_if_->write();
    //get marker from img
//    get_marker();

//    this->tag_interfaces->update_blackboard(this->markers_);

    cfg_mutex.unlock();
}

//void
//ConveyorVisionThread::get_marker()
//{
//    // detect makres on image
////    detector.Detect(ipl,&alvar_cam);
//    // reset currently saved markers
//    this->markers_->clear();
//    // fill output array
//    for(alvar::MarkerData &tmp_marker: *(this->detector.markers))
//    {
//        Pose tmp_pose = tmp_marker.pose;
//        //skip the marker, if the pose is directly on the camera (error)
//        if(tmp_pose.translation[0]<1 && tmp_pose.translation[1]<1 && tmp_pose.translation[2]<1){
//            continue;
//        }
//        this->markers_->push_back(tmp_marker);
//        // add up to markers
//        tmp_marker.Visualize(ipl,&alvar_cam);
//    }
//    firevision::IplImageAdapter::convert_image_yuv422_planar(ipl,image_buffer);
//}

// config handling
void ConveyorVisionThread::config_value_erased(const char *path) {};
void ConveyorVisionThread::config_tag_changed(const char *new_tag) {};
void ConveyorVisionThread::config_comment_changed(const fawkes::Configuration::ValueIterator *v) {};
void ConveyorVisionThread::config_value_changed(const fawkes::Configuration::ValueIterator *v)
{
  load_config();
}

void ConveyorVisionThread::load_config()
{
  if(cfg_mutex.try_lock()){
    try{
      std::string prefix = CFG_PREFIX;
      // log, that we open load the config
      logger->log_info(name(),"loading config");
      shm_id = config->get_string((prefix + "shm_image_id").c_str());
      obj_realworld_distance = config->get_float((prefix + "obj_realworld_distance").c_str());
      obj_realworld_pixels = config->get_float((prefix + "obj_realworld_pixels").c_str());
      obj_realworld_width = config->get_float((prefix + "obj_realworld_width").c_str());
      num_frames_for_average = config->get_int((prefix + "num_frames_for_average").c_str());
      conveyor_distance_threshold = config->get_float((prefix + "conveyor_distance_threshold").c_str());
      visualization_enabled = config->get_bool((prefix + "visualization_enabled").c_str());
      
      use_hough_lines_ = config->get_bool((prefix + "/houghlines/use_hough_line_optimization").c_str());
      if (use_hough_lines_) {
        hough_lines_averaging_count_ = config->get_uint((prefix + "houghlines/hough_lines_averaging_count").c_str());

        binary_threshold_min_ = config->get_int((prefix + "houghlines/binary_threshold_min").c_str());
        binary_threshold_max_ = config->get_int((prefix + "houghlines/binary_threshold_max").c_str());
        binary_threshold_average_min_ = config->get_int((prefix + "houghlines/binary_threshold_average_min").c_str());
        binary_threshold_average_max_ = config->get_int((prefix + "houghlines/binary_threshold_average_max").c_str());
        max_binary_value_ = config->get_int((prefix + "houghlines/max_binary_value").c_str());
        threshold_type_ = config->get_int((prefix + "houghlines/threshold_type").c_str());
        morph_element_ = config->get_int((prefix + "houghlines/morph_element").c_str());
        morph_size_ = config->get_int((prefix + "houghlines/morph_size").c_str());
        morph_operator_ = config->get_int((prefix + "houghlines/morph_operator").c_str());
        canny_threshold_ = config->get_int((prefix + "houghlines/canny_threshold").c_str());
        line_mean_ = config->get_uint((prefix + "houghlines/line_mean").c_str());
        conveyor_realworld_distance = config->get_float((prefix + "houghlines/conveyor_realworld_distance").c_str());
        conveyor_realworld_pixels = config->get_float((prefix + "houghlines/conveyor_realworld_pixels").c_str());
        conveyor_realworld_width = config->get_float((prefix + "houghlines/conveyor_realworld_width").c_str());
      }
      // load alvar camera calibration
//      alvar_cam.SetCalib(config->get_string((prefix + "alvar_camera_calib_file").c_str()).c_str(),0,0,FILE_FORMAT_DEFAULT);
      // load marker size and apply it
//      marker_size = config->get_uint((prefix + "marker_size").c_str());
//      detector.SetMarkerSize(marker_size);
    }
    catch(fawkes::Exception &e){
      logger->log_error(name(), e);
    }
  }
  // gets called for every changed entry... so init is called once per change.
  cfg_mutex.unlock();
}

/** @function detectAndDisplay */
void ConveyorVisionThread::detect()
{
  std::vector<Rect> faces;
  Mat frame_gray;

  cvtColor( frame, frame_gray, CV_BGR2GRAY );
  equalizeHist( frame_gray, frame_gray );

  //-- Detect faces
  mps_cascade.detectMultiScale( frame_gray, faces, 1.1, 2, 0|CV_HAAR_SCALE_IMAGE, Size(30, 30) );
  int visibility_history = mps_conveyor_if_->visibility_history();
  
//  logger->log_info(name(), "got %d faces", faces.size());
  // ignore images that probably contain more than one conveyor
  if (faces.size() == 1) {
    // width of object at one meters distance
    
    float focal_length = (obj_realworld_pixels * obj_realworld_distance) / obj_realworld_width;
    float d_dash = (focal_length * obj_realworld_width) / faces[0].width;

//    float beta = (asin(W/d_dash) * 180) / M_PI;
    float beta = asin(obj_realworld_width / d_dash);

    float multiplier = frame.cols / faces[0].width;
    float overall_open_angle = beta * multiplier;

    // center position of predRect relative to the middle of the image.
    float center_x = faces[0].x + faces[0].width / 2 - frame.cols / 2;
    float pixels_x_per_degree = frame.cols / overall_open_angle;
    float center_x_angle = center_x / pixels_x_per_degree;
    float world_pos_x = (sin(center_x_angle) * d_dash) / 100;
    
    // center position of predRect relative to the middle of the image.
    float center_y = faces[0].y + faces[0].height / 2 - frame.rows / 2;
    float pixels_y_per_degree = frame.rows / overall_open_angle;
    float center_y_angle = center_y / pixels_y_per_degree;
    float world_pos_y = -(sin(center_y_angle) * d_dash) / 100;
    
    float world_pos_z = sqrt(d_dash*d_dash + world_pos_x*world_pos_x) / 100;
    if (world_pos_z > conveyor_distance_threshold)
      return;
    
    world_pos_z_measurements.push_front(world_pos_z);
    if (world_pos_z_measurements.size() > num_frames_for_average)
    {
      world_pos_z_measurements.pop_back();
    }
    
    for (size_t i = 0; i < world_pos_z_measurements.size(); i++)
    {
      world_pos_z_average += world_pos_z_measurements[i];
    }
    world_pos_z_average /= world_pos_z_measurements.size();
    
//    float focal_length_mm = 50;
//    float obj_height_mm = 50;
//    float im_height_px = frame.rows;
//    float obj_height_px = faces[0].height;
//    float sensor_height_mm = 2; // 1/4" in mm
//    float height_width_sqrt = sqrt(frame.rows * frame.rows + frame.cols * frame.cols);
//    float opening_angle = 0.86325;
//    float pixels_per_rad = opening_angle / height_width_sqrt;
////    float norm_width = 0.47 / 78;
////    float norm_height = 0.4 / 85;
//    Point center( faces[0].x + faces[0].width*0.5, faces[0].y + faces[0].height*0.5 );
//    float dist_from_center_px = frame.cols / 2 - center.x;
//    float obj_deg = -(dist_from_center_px * pixels_per_rad);
//    float distance = (focal_length_mm * obj_height_mm * im_height_px) / (obj_height_px * sensor_height_mm);
    
//    printf("found face: x: %d, y: %d, width: %d, height: %d distance:%f, obj_deg: %f\n", faces[0].x, faces[0].y, faces[0].width, faces[0].height, distance, obj_deg);
//    logger->log_info(name(), "Found conveyor: x= %f, y= %f, z= %f", world_pos_z_average, world_pos_z, world_pos_y);
    
    if (use_hough_lines_)
      {


      Rect myROI(faces[0].x, faces[0].y, faces[0].width, faces[0].height);
      Mat croppedImage = frame(myROI);
      cvtColor( croppedImage, croppedImage, CV_BGR2GRAY );

      // calculate binarization threshold depending on average gray-value in the image
      Scalar the_mean = mean(croppedImage);
      float float_mean = the_mean.val[0];

      int calculated_threshold = binary_threshold_min_;
      if (float_mean >= binary_threshold_average_min_ && float_mean <= binary_threshold_average_max_)
      {
        calculated_threshold += (float_mean - binary_threshold_average_min_);
      }
      else if (float_mean > binary_threshold_average_max_)
      {
        calculated_threshold = binary_threshold_max_;
      }

      int thresh = 200;
      /// Detect edges using canny
      Mat dst, cdst;
      threshold( croppedImage, dst, calculated_threshold, max_binary_value_, threshold_type_);
      Canny( dst, dst, thresh, thresh*2, 7 );

      int operation = morph_operator_ + 2;

      Mat element = getStructuringElement( morph_element_, Size( 2*morph_size_ + 1, 2*morph_size_+1 ), Point( morph_size_, morph_size_ ) );

      // Apply the specified morphology operation
      morphologyEx( dst, dst, operation, element );
      int roi_width_limiter = dst.cols / 4.2; // 10 percent of width of image
      int roi_height_limiter = dst.rows / 4.8; // 10 percent of width of image

      // fill left side
      rectangle(dst, Point(0, 0), Point(roi_width_limiter, dst.rows), Scalar(0,0,0), CV_FILLED);
      // fill right side
      rectangle(dst, Point(dst.cols - roi_width_limiter, 0), Point(dst.cols, dst.rows), Scalar(0,0,0), CV_FILLED);
      // fill top
      rectangle(dst, Point(0, 0), Point(dst.cols, roi_height_limiter), Scalar(0,0,0), CV_FILLED);
      // fill middle
      rectangle(dst, Point(dst.cols / 2 - 1.5 * (dst.cols / 8), 0), Point(dst.cols / 2 + 1.5 * (dst.cols / 8), dst.rows), Scalar(0,0,0), CV_FILLED);

      vector<Vec4i> lines;
      cvtColor(dst, cdst, CV_GRAY2BGR);

      double rho = 1;
      double theta = CV_PI / 180;
      double minLineLength = 10;
      double maxLineGap = 25;
      int hough_threshold = 20;

      HoughLinesP(dst, lines, rho, theta, hough_threshold, minLineLength, maxLineGap );

      int nearest_line_left_offset = 0;
      int nearest_line_right_offset = dst.cols;
      int nearest_line_left_index = 0;
      int nearest_line_right_index = 0;

      vector<Vec4i> vertical_lines;

      for( size_t j = 0; j < lines.size(); j++ )
      {
        Vec4i l = lines[j];

        // is vertically oriented line?
        if (abs(l[1] - l[3]) > 20)
        {
          if (l[0] > l[2])
          {
            int diff = (l[0] - l[2]) / 2;
            l[0] -= diff;
            l[2] += diff;
          }
          else
          {
            int diff = (l[2] - l[0]) / 2;
            l[0] += diff;
            l[2] -= diff;
          }
          vertical_lines.push_back(l);
        }
      }
      for (size_t iV = 0; iV < vertical_lines.size(); iV++)
      {
        Vec4i l = vertical_lines[iV];
          if (l[0] > nearest_line_left_offset && !(l[0] > dst.cols / 2))
          {
            nearest_line_left_offset = l[0];
            nearest_line_left_index = iV;
          }
          if (l[0] < nearest_line_right_offset && !(l[0] < dst.cols / 2))
          {
            nearest_line_right_offset = l[0];
            nearest_line_right_index = iV;
          }
      }

      // fail if no vertical lines detected or if horizontal distance between lines is too low
      if(vertical_lines.size() > 0
              && 
              abs(vertical_lines[nearest_line_left_index][0] - vertical_lines[nearest_line_right_index][0]) > 20)
      {
        int horizontal_diff = abs(vertical_lines[nearest_line_left_index][0] - vertical_lines[nearest_line_right_index][0]);
        int horizontal_start = vertical_lines[nearest_line_left_index][0];
        int vertical_start = abs(vertical_lines[nearest_line_left_index][1] - vertical_lines[nearest_line_left_index][3]);
        conveyor_average_horizontal_diff.push_front(horizontal_diff);
        conveyor_average_horizontal_start.push_front(horizontal_start);
        conveyor_average_vertical_start.push_front(vertical_start);
      }
      if (conveyor_average_horizontal_diff.size() > line_mean_)
      {
        conveyor_average_horizontal_diff.pop_back();
      }
      if (conveyor_average_horizontal_start.size() > line_mean_)
      {
        conveyor_average_horizontal_start.pop_back();
      }
      if (conveyor_average_vertical_start.size() > line_mean_)
      {
        conveyor_average_vertical_start.pop_back();
      }

      int vert_start = 0;
      int hor_start = 0;
      int hor_diff = 0;

      for (size_t i = 0; i < conveyor_average_horizontal_diff.size(); i++)
      {
        vert_start += conveyor_average_vertical_start[i];
        hor_start += conveyor_average_horizontal_start[i];
        hor_diff += conveyor_average_horizontal_diff[i];
      }

      if (conveyor_average_vertical_start.size() > 0)
      {
        vert_start = vert_start / conveyor_average_vertical_start.size();
        hor_start = hor_start / conveyor_average_horizontal_start.size();
        hor_diff = hor_diff / conveyor_average_horizontal_diff.size();

        line( frame, Point(faces[0].x + hor_start, faces[0].y + vert_start), Point(faces[0].x + hor_start + hor_diff, faces[0].y + vert_start), Scalar(255,255,0), 3, CV_AA); 
      }

      float focal_length = (conveyor_realworld_pixels * conveyor_realworld_distance) / conveyor_realworld_width;
      float d_dash = (focal_length * conveyor_realworld_width) / hor_diff;

      float beta = asin(conveyor_realworld_width / d_dash);

      float multiplier = frame.cols / faces[0].width;
      float overall_open_angle = beta * multiplier;
      // center position of predRect relative to the middle of the image.
      float center_x = faces[0].x + hor_start + hor_diff/2;
      float pixels_x_per_degree = frame.cols / overall_open_angle;
      float center_x_angle = center_x / pixels_x_per_degree;
      world_pos_x = sin(center_x_angle) * d_dash;

      world_pos_z_average = sqrt(d_dash*d_dash + world_pos_x*world_pos_x);
      }
    mps_conveyor_if_->set_translation(0, world_pos_z_average);
    mps_conveyor_if_->set_translation(1, world_pos_x);
    mps_conveyor_if_->set_translation(2, world_pos_y);
    mps_conveyor_if_->set_rotation(0, 0);
    mps_conveyor_if_->set_rotation(1, 0);
    //interface->set_timestamp(&p->cart.stamp);
    mps_conveyor_if_->set_frame("base_conveyor");
    mps_conveyor_if_->set_visibility_history(visibility_history);
    if (visibility_history >= 0) {
      mps_conveyor_if_->set_visibility_history(visibility_history + 1);
    } else {
      mps_conveyor_if_->set_visibility_history(1);
    }
    if (visualization_enabled)
    {
      cv::rectangle(frame, Point(faces[0].x, faces[0].y), Point(faces[0].x + faces[0].width, faces[0].y + faces[0].height), Scalar(255,0,0), 1);
      cvReleaseImage(&ipl);
      ipl = cvCreateImage(cvSize(frame.cols,frame.rows),8,3);
      Mat newC = cvarrToMat(ipl);
      *ipl = newC;
      firevision::IplImageAdapter::convert_image_yuv422_planar(ipl,image_buffer);      
    }
  } else {
    // conveyor not visible
    if (visibility_history <= 0) {
            mps_conveyor_if_->set_visibility_history(visibility_history - 1);
    } else {
            mps_conveyor_if_->set_visibility_history(-1);
            world_pos_z_measurements.clear();
    }

  }
  
 }
