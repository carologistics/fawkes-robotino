{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6408,"status":"ok","timestamp":1713377124006,"user":{"displayName":"Lucas Johannsen","userId":"07592773719191891789"},"user_tz":-120},"id":"8bjM03g-M8hG","outputId":"c24daaf7-6114-45c5-9a75-6c69aa6b8938"},"outputs":[],"source":["import os\n","from ultralytics import YOLO"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":106437,"status":"ok","timestamp":1709485985263,"user":{"displayName":"Lucas Johannsen","userId":"07592773719191891789"},"user_tz":-60},"id":"P6GdSP55P6pN","outputId":"a4ee33e1-3c6c-4ee4-ac9f-3a9e18f11f26"},"outputs":[],"source":["import os\n","import shutil\n","\n","def copy_images(source_dir, target_dir, image_extensions={'jpg', 'JPG', 'jpeg', 'png', 'gif', 'bmp'}):\n","    \"\"\"\n","    Copies image files from source_dir to target_dir, preserving the subdirectory structure.\n","\n","    :param source_dir: Path to the source directory.\n","    :param target_dir: Path to the target directory where images will be copied.\n","    :param image_extensions: A set of image file extensions to look for.\n","    \"\"\"\n","    for root, dirs, files in os.walk(source_dir):\n","        # Determine the path to the current directory relative to the source directory\n","        rel_path = os.path.relpath(root, source_dir)\n","        target_path = os.path.join(target_dir, rel_path)\n","\n","        # Ensure the target directory exists\n","        os.makedirs(target_path, exist_ok=True)\n","\n","        for file in files:\n","            if file.split('.')[-1].lower() in image_extensions:\n","                source_file = os.path.join(root, file)\n","                target_file = os.path.join(target_path, file)\n","\n","                # Copy the image file to the target directory\n","                shutil.copy(source_file, target_file)\n","                print(f\"Copied {source_file} to {target_file}\")\n","\n","# Example usage\n","\n","source_directory = \"../Data/ROBOTS/labels\"\n","target_directory = \"../Data/ROBOTS/images\"\n","copy_images(source_directory, target_directory)\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":367},"executionInfo":{"elapsed":9,"status":"error","timestamp":1713377124007,"user":{"displayName":"Lucas Johannsen","userId":"07592773719191891789"},"user_tz":-120},"id":"WoBz6wy2mnPn","outputId":"2af27c00-9f95-4079-90f2-f17bdd0adc92"},"outputs":[],"source":["import torch\n","if torch.cuda.is_available():\n","    torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":443},"executionInfo":{"elapsed":8,"status":"error","timestamp":1713377124007,"user":{"displayName":"Lucas Johannsen","userId":"07592773719191891789"},"user_tz":-120},"id":"QvDO6-fYNfy5","outputId":"a1e8a51e-69a1-4b8d-ec56-5361de276ac5"},"outputs":[{"name":"stdout","output_type":"stream","text":["model loaded, ultra\n","New https://pypi.org/project/ultralytics/8.2.1 available üòÉ Update with 'pip install -U ultralytics'\n","Ultralytics YOLOv8.2.0 üöÄ Python-3.12.2 torch-2.2.2+cu121 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 5719MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=dataset.yaml, epochs=20, time=None, patience=100, batch=32, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train3\n","WARNING ‚ö†Ô∏è renaming data YAML 'validation' key to 'val' to match YOLO format.\n","Overriding model.yaml nc=80 with nc=3\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n","Model summary: 225 layers, 3011433 parameters, 3011417 gradients, 8.2 GFLOPs\n","\n","Transferred 319/355 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/henningarbeit/Documents/yolo/training_stuffu/datasets/augmented_set.cache... 200 images, 12 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /home/henningarbeit/Documents/yolo/training_stuffu/datasets/test_set.cache... 409 images, 1 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 409/409 [00:00<?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Plotting labels to runs/detect/train3/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/detect/train3\u001b[0m\n","Starting training for 20 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       1/20      4.27G      1.712      4.191      1.795         20        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.02it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  4.04it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all        409        656    0.00222      0.294     0.0133    0.00853\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       2/20      4.28G      1.201      3.642      1.308         16        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  4.72it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  4.26it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        409        656    0.00265      0.328      0.102     0.0841\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       3/20      4.28G     0.9778      2.537       1.08         20        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  4.71it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  4.36it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        409        656    0.00287      0.347       0.19     0.0908\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       4/20      4.28G     0.8981      1.955      1.015         21        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  4.82it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  4.47it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        409        656      0.703       0.18      0.343      0.249\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       5/20      4.28G     0.9075      1.568     0.9972         19        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  4.81it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  4.59it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        409        656          1     0.0521      0.426      0.294\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       6/20      4.28G     0.8535      1.303     0.9966         20        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  4.82it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  4.49it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        409        656      0.994      0.115      0.332       0.27\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       7/20      4.28G     0.8341      1.319      1.005         13        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  4.81it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  4.64it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        409        656      0.997      0.129       0.26       0.21\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       8/20      4.29G     0.8421       1.22     0.9792         28        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  4.92it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  4.62it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        409        656      0.948      0.162      0.451      0.355\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       9/20      4.28G     0.7848      1.146     0.9581         21        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  4.96it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  4.69it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        409        656      0.925      0.132      0.374      0.301\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      10/20       4.3G     0.7976      1.136     0.9617         25        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  4.92it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  4.79it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        409        656      0.979      0.147      0.415      0.339\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["Closing dataloader mosaic\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      11/20      4.28G     0.7388      1.495      0.963         11        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.42it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  4.76it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        409        656       0.91     0.0897      0.257        0.2\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      12/20       4.3G     0.7122      1.412     0.9456          8        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  4.95it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  4.72it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        409        656      0.964      0.151      0.318      0.257\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      13/20      4.28G     0.7402      1.301     0.9751         11        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  5.00it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  4.79it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        409        656      0.863      0.112      0.285       0.23\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      14/20       4.3G     0.7082      1.274     0.9364         11        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  4.94it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  4.77it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        409        656        0.9      0.196      0.295      0.243\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      15/20      4.28G     0.7195      1.239     0.9714         10        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  5.00it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  5.00it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        409        656      0.894      0.186      0.341      0.273\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      16/20       4.3G     0.6857      1.251     0.9456         10        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  4.95it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  5.03it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        409        656       0.96      0.463      0.534      0.433\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      17/20      4.28G     0.6838      1.137     0.9067         15        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  4.99it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  4.93it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        409        656       0.94       0.51      0.545      0.446\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      18/20       4.3G     0.6842      1.157     0.9292         10        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  4.92it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  5.05it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        409        656      0.964      0.549      0.583      0.471\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      19/20      4.28G     0.6147       1.08     0.8999         12        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  4.98it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  4.97it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        409        656      0.967      0.564      0.601      0.484\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      20/20       4.3G     0.6032      1.033     0.9102         11        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  4.95it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  5.03it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        409        656      0.968      0.581      0.613      0.491\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","20 epochs completed in 0.019 hours.\n","Optimizer stripped from runs/detect/train3/weights/last.pt, 6.2MB\n","Optimizer stripped from runs/detect/train3/weights/best.pt, 6.2MB\n","\n","Validating runs/detect/train3/weights/best.pt...\n","Ultralytics YOLOv8.2.0 üöÄ Python-3.12.2 torch-2.2.2+cu121 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 5719MiB)\n","Model summary (fused): 168 layers, 3006233 parameters, 0 gradients, 8.1 GFLOPs\n","WARNING ‚ö†Ô∏è renaming data YAML 'validation' key to 'val' to match YOLO format.\n"]},{"name":"stderr","output_type":"stream","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  3.90it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all        409        656      0.969       0.58      0.613       0.49\n","              conveyor        409        349      0.923      0.887      0.933      0.757\n","             workpiece        409        282      0.984      0.852      0.907      0.714\n","                 slide        409         25          1          0          0          0\n","Speed: 0.2ms preprocess, 1.4ms inference, 0.0ms loss, 1.0ms postprocess per image\n","Results saved to \u001b[1mruns/detect/train3\u001b[0m\n","model trained, ultra\n"]}],"source":["model = YOLO('yolov8n.pt')\n","print(\"model loaded, ultra\")\n","results = model.train(data='dataset.yaml', epochs=20, batch = 32)\n","print(\"model trained, ultra\")"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[ WARN:0@1739.816] global cap_v4l.cpp:997 open VIDEOIO(V4L2:/dev/video1): can't open camera by index\n","[ERROR:0@1739.929] global obsensor_uvc_stream_channel.cpp:159 getStreamChannelGroup Camera index out of range\n"]}],"source":["import cv2\n","from PIL import Image\n","\n","video=cv2.VideoCapture(1)\n","\n","while video.isOpened():\n","    success,frame = video.read()\n","\n","    if success:\n","        results=model.track(frame, persist=True)\n","\n","        a = results[0].plot()\n","        cv2.imshow(a)\n","        if cv2.waitKey(1)  & 0xFF== ord('q'):\n","            break\n","    else:\n","        break\n","\n","video.release()\n","cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Ultralytics YOLOv8.2.0 üöÄ Python-3.12.2 torch-2.2.2+cu121 CPU (AMD Ryzen 9 5900HX with Radeon Graphics)\n","Model summary (fused): 168 layers, 3006233 parameters, 0 gradients, 8.1 GFLOPs\n","\n","\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'runs/detect/train3/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 7, 8400) (5.9 MB)\n","\n","\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.16.0 opset 17...\n","\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 0.4s, saved as 'runs/detect/train3/weights/best.onnx' (11.7 MB)\n","\n","Export complete (1.7s)\n","Results saved to \u001b[1m/home/henningarbeit/Documents/yolo/training_stuffu/runs/detect/train3/weights\u001b[0m\n","Predict:         yolo predict task=detect model=runs/detect/train3/weights/best.onnx imgsz=640  \n","Validate:        yolo val task=detect model=runs/detect/train3/weights/best.onnx imgsz=640 data=dataset.yaml  \n","Visualize:       https://netron.app\n"]},{"data":{"text/plain":["'runs/detect/train3/weights/best.onnx'"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["newmodel=YOLO(model='runs/detect/train3/weights/best.pt')\n","newmodel.export(format='onnx')"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","image 1/1 /home/henningarbeit/Documents/yolo/training_stuffu/datasets/test_set/detect_mini26.jpg: 480x640 1 conveyor, 1 workpiece, 4.9ms\n","Speed: 18.3ms preprocess, 4.9ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n"]},{"data":{"text/plain":["[ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'conveyor', 1: 'workpiece', 2: 'slide'}\n"," obb: None\n"," orig_img: array([[[176,  58, 171],\n","         [163,  67, 151],\n","         [112,  57,  84],\n","         ...,\n","         [ 95,  95,  83],\n","         [ 90,  91,  81],\n","         [ 92,  93,  84]],\n"," \n","        [[133,  36, 122],\n","         [127,  48, 111],\n","         [103,  62,  77],\n","         ...,\n","         [ 93,  95,  83],\n","         [ 90,  91,  82],\n","         [ 91,  92,  83]],\n"," \n","        [[116,  63,  96],\n","         [113,  73,  91],\n","         [110,  93,  84],\n","         ...,\n","         [ 95,  96,  87],\n","         [ 93,  94,  85],\n","         [ 91,  93,  87]],\n"," \n","        ...,\n"," \n","        [[154, 155, 153],\n","         [156, 157, 155],\n","         [154, 155, 153],\n","         ...,\n","         [231, 238, 225],\n","         [234, 238, 227],\n","         [254, 255, 245]],\n"," \n","        [[161, 160, 156],\n","         [163, 162, 158],\n","         [161, 160, 156],\n","         ...,\n","         [250, 255, 252],\n","         [250, 255, 253],\n","         [247, 252, 250]],\n"," \n","        [[165, 165, 159],\n","         [167, 167, 161],\n","         [169, 166, 162],\n","         ...,\n","         [238, 249, 246],\n","         [249, 254, 255],\n","         [249, 254, 255]]], dtype=uint8)\n"," orig_shape: (480, 640)\n"," path: '/home/henningarbeit/Documents/yolo/training_stuffu/datasets/test_set/detect_mini26.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/train23'\n"," speed: {'preprocess': 18.31793785095215, 'inference': 4.907846450805664, 'postprocess': 0.8492469787597656}]"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["model.predict('datasets/test_set/detect_mini26.jpg')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u2u2_cUydVqy"},"outputs":[],"source":["model = YOLO('yolov8n.pt')\n","print(\"model loaded, ultra\")\n","results = model.train(data='dataset.yaml', epochs=3)\n","print(\"model trained, ultra\")\n","\n","results = model.train(data='dataset.yaml', epochs=3)\n","\n","\n","\n","\n","\n","\n","\n","# Assuming 'dataset.yaml' is in the 'ros2_ws/data/MPS_Detection/' directory\n","dataset_path = 'ros2_ws/data/MPS_Detection/dataset.yaml'\n","\n","# Load the pre-trained model\n","model = torch.hub.load('ultralytics/yolov5', 'yolov5n', pretrained=True)\n","\n","# Configure for custom dataset training\n","model.classes = 7  # Number of classes in your dataset\n","\n","# Training parameters (customize as needed)\n","batch_size = 16  # Adjust based on your GPU memory\n","img_size = 640  # Commonly used size for YOLOv5\n","epochs = 100  # Number of training epochs\n","\n","# Start training\n","results = model.train(data=dataset_path,\n","                      imgsz=img_size,\n","                      batch_size=batch_size,\n","                      epochs=epochs)\n","\n","print(\"Training completed.\")\n","\n","\n","\n","\n","\n","\n","\n","\n","import torch\n","import os\n","\n","# Model\n","model = torch.hub.load('ultralytics/yolov5', 'yolov5n', pretrained=True, classes = 7)\n","\n","print(\"model_loaded\")\n","\n","\n","# Train the model using the 'coco128.yaml' dataset for 3 epochs\n","results = model.train(data='dataset.yaml', epochs=3)\n","\n","\n","# pathing\n","current_file_path = os.path.abspath(__file__)\n","\n","package_path = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(current_file_path)))))\n","\n","data_path = os.path.join(package_path, 'ros2_ws/data/MPS_Detection/rcll dataset', 'some_correct_file')\n","\n","\n","\n","# pathing\n","current_file_path = os.path.abspath(__file__)\n","\n","package_path = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(current_file_path)))))\n","\n","print(\"pathing_done\")\n","# load model files\n","#model = os.path.join(package_path, 'ros2_ws/src/ros2_markerless_mps/model', 'rtmdet_tiny_fast_rcll.py')\n","\n","model_file = os.path.join(package_path, 'ros2_ws/src/ros2_markerless_mps/model', 'rcll.pth')\n","print(\"files available\")\n","ckp = torch.load(model_file, map_location='cpu')\n","\n","model_state_dict = ckp['state_dict']\n","\n","model.load_state_dict(model_state_dict)\n","\n","print(\"model_conigured\")"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMVf+JwKSeZ30UPV4WzBHsq","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":0}
